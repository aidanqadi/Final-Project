{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "baea55bf",
      "metadata": {
        "id": "baea55bf"
      },
      "source": [
        "# Final Project Notebook — Aidan\n",
        "\n",
        "_Date: August 17, 2025_\n",
        "\n",
        "\n",
        "This notebook consolidates prior milestones into a complete end‑to‑end project:\n",
        "\n",
        "- Import & setup\n",
        "- Data loading\n",
        "- Initial exploratory data analysis (EDA)\n",
        "- Data cleaning\n",
        "- Analysis & visualization to answer **at least four** business questions\n",
        "- Conclusions, recommendations, and future work\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e34e08",
      "metadata": {
        "id": "98e34e08"
      },
      "source": [
        "\n",
        "## 1) Project Overview\n",
        "\n",
        "**Client (who benefits):**  An online retail company looking to optimize its product mix, customer outreach, and\n",
        "international expansion\n",
        "\n",
        "**Business context / value:** Inventory optimization through identification of best-selling items and seasonal trends\n",
        "* Targeted marketing via customer segmentation (RFM)\n",
        "* Strategic growth by pinpointing lucrative overseas markets\n",
        "* Pricing strategy insights by understanding price–volume dynamics>_\n",
        "**Questions to answer:\n",
        "1. _Q1_ Which products generate the most revenue?\n",
        "2. _Q2_  How do sales trend over time?\n",
        "\n",
        "3. _Q3_  How can customers be segmented by RFM (Recency, Frequency, Monetary)?\n",
        "4. _Q4_ 4. Which countries (outside the UK) contribute most to international revenue?\n",
        "5. ._Q5_  What’s the relationship between unit price and quantity sold?\n",
        "\n",
        "**Tools**\n",
        "- Python (pandas, numpy, matplotlib)\n",
        "- Jupyter Notebook\n",
        "- Optional: seaborn, scikit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8c1dc2c",
      "metadata": {
        "id": "d8c1dc2c"
      },
      "source": [
        "## Load your data\n",
        "\n",
        "Choose one of the two options below:\n",
        "\n",
        "- **Option A (Local path):** set `DATA_PATH` to your file (CSV or XLSX).\n",
        "- **Option B (Colab upload):** leave `DATA_PATH=None` and run; you'll be prompted to upload.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "697f825d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "697f825d",
        "outputId": "d1c1e177-8501-4059-bf13-7ba096720d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your CSV / CSV.GZ / XLSX file…\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-87b82eec-a584-49c9-9c69-00e32f851c7c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-87b82eec-a584-49c9-9c69-00e32f851c7c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import io, os\n",
        "\n",
        "# Detect Colab\n",
        "try:\n",
        "    from google.colab import files  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "DEFAULT_NAME = \"online_retail_sample_10k_clean.csv\"  # change if needed\n",
        "\n",
        "def _read_any(path_or_buf, filename_hint=\"\"):\n",
        "    \"\"\"Read CSV/CSV.GZ/Excel into a DataFrame.\"\"\"\n",
        "    name = (filename_hint or (str(path_or_buf) if isinstance(path_or_buf, str) else \"\"))\n",
        "    lower = name.lower()\n",
        "    if lower.endswith((\".xlsx\", \".xls\")):\n",
        "        return pd.read_excel(path_or_buf)\n",
        "    comp = \"gzip\" if lower.endswith(\".gz\") else \"infer\"\n",
        "    return pd.read_csv(path_or_buf, compression=comp, low_memory=False, encoding=\"latin1\")\n",
        "\n",
        "# ==== PROMPT & LOAD ====\n",
        "if os.path.exists(DEFAULT_NAME):\n",
        "    print(f\"Found {DEFAULT_NAME} in the working directory. Loading it…\")\n",
        "    df_raw = _read_any(DEFAULT_NAME, filename_hint=DEFAULT_NAME)\n",
        "\n",
        "elif IN_COLAB:\n",
        "    print(\"Please upload your CSV / CSV.GZ / XLSX file…\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        raise SystemExit(\"No file uploaded.\")\n",
        "    name, data = next(iter(uploaded.items()))\n",
        "    buf = io.BytesIO(data)\n",
        "    df_raw = _read_any(buf, filename_hint=name)\n",
        "    print(f\"Loaded: {name}  -> shape={df_raw.shape}\")\n",
        "\n",
        "else:\n",
        "    # Local Jupyter: file dialog with fallback to manual path\n",
        "    path = \"\"\n",
        "    try:\n",
        "        import tkinter as tk\n",
        "        from tkinter import filedialog\n",
        "        tk.Tk().withdraw()\n",
        "        path = filedialog.askopenfilename(\n",
        "            title=\"Select CSV/CSV.GZ or Excel file\",\n",
        "            filetypes=[(\"CSV\", \"*.csv\"), (\"Compressed CSV\", \"*.csv.gz\"),\n",
        "                       (\"Excel\", \"*.xlsx *.xls\"), (\"All files\", \"*.*\")]\n",
        "        )\n",
        "    except Exception:\n",
        "        pass\n",
        "    if not path:\n",
        "        path = input(\"Enter path to your CSV/CSV.GZ or Excel file: \").strip()\n",
        "    if not path:\n",
        "        raise SystemExit(\"No file selected.\")\n",
        "    df_raw = _read_any(path, filename_hint=os.path.basename(path))\n",
        "    print(f\"Loaded: {os.path.basename(path)}  -> shape={df_raw.shape}\")\n",
        "\n",
        "print(\"Initial shape:\", df_raw.shape)\n",
        "df_raw.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9104efbe",
      "metadata": {
        "id": "9104efbe"
      },
      "source": [
        "#### Detected data‑loader snippet(s) from Milestone 4 (for reference)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eed452d",
      "metadata": {
        "id": "1eed452d"
      },
      "source": [
        "## Initial EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74ac0063",
      "metadata": {
        "id": "74ac0063"
      },
      "outputs": [],
      "source": [
        "# Basic shape & columns\n",
        "try:\n",
        "    print(\"Shape:\", df.shape)\n",
        "    print(\"Columns:\", list(df.columns))\n",
        "except NameError:\n",
        "    print(\"⚠️ Define df first in the Data Loading section.\")\n",
        "\n",
        "# Types, info, samples\n",
        "try:\n",
        "    print(\"\\nDTypes:\")\n",
        "    print(df.dtypes)\n",
        "    print(\"\\nInfo:\")\n",
        "    print(df.info())\n",
        "    display(df.head(10))\n",
        "    display(df.tail(5))\n",
        "    display(df.sample(min(5, len(df))))\n",
        "except Exception as e:\n",
        "    print(\"EDA preview error:\", e)\n",
        "\n",
        "# Descriptive statistics (numeric & object separately for clarity)\n",
        "try:\n",
        "    display(df.describe(include=[np.number]).T)\n",
        "    display(df.describe(include=[object]).T)\n",
        "except Exception as e:\n",
        "    print(\"Describe error:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0964e81",
      "metadata": {
        "id": "f0964e81"
      },
      "source": [
        "## 5) Data Cleaning PT.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2622e219",
      "metadata": {
        "id": "2622e219"
      },
      "source": [
        "\n",
        "Describe the cleaning decisions you made and **why** (NaNs, outliers, type fixes, merges, renames, splits, standardization):\n",
        "\n",
        "- _Example_: Dropped rows with invalid dates because ...\n",
        "- _Example_: Imputed missing unit price with median by country because ...\n",
        "- _Example_: Standardized country names ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8cedf65",
      "metadata": {
        "id": "d8cedf65"
      },
      "source": [
        "### From dedicated cleaning notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a2173f",
      "metadata": {
        "id": "c2a2173f"
      },
      "outputs": [],
      "source": [
        "missing_counts = df.isna().sum().sort_values(ascending=False)\n",
        "missing_counts[missing_counts > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa84b99",
      "metadata": {
        "id": "0fa84b99"
      },
      "outputs": [],
      "source": [
        "# Example cleaning: Drop rows missing CustomerID (common in this dataset for incomplete transactions)\n",
        "if 'CustomerID' in df.columns:\n",
        "    df = df.dropna(subset=['CustomerID'])\n",
        "print('After dropping missing CustomerID:', df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceeefc6a",
      "metadata": {
        "id": "ceeefc6a"
      },
      "outputs": [],
      "source": [
        "# Fill missing descriptions if StockCode is present but Description is NaN (optional strategy)\n",
        "if 'Description' in df.columns and 'StockCode' in df.columns:\n",
        "    df['Description'] = df['Description'].fillna('No description')\n",
        "df['Description'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b225d05",
      "metadata": {
        "id": "1b225d05"
      },
      "outputs": [],
      "source": [
        "dup_count = df.duplicated().sum()\n",
        "print('Duplicate rows:', dup_count)\n",
        "df = df.drop_duplicates()\n",
        "print('After removing duplicates:', df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65734b5f",
      "metadata": {
        "id": "65734b5f"
      },
      "outputs": [],
      "source": [
        "# Check basic stats\n",
        "df[['Quantity', 'UnitPrice']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58ad5644",
      "metadata": {
        "id": "58ad5644"
      },
      "outputs": [],
      "source": [
        "# Remove rows with non-positive Quantity or UnitPrice (common cleaning choice for sales analysis)\n",
        "df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
        "print('After removing non-positive Quantity/UnitPrice:', df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8860aef2",
      "metadata": {
        "id": "8860aef2"
      },
      "outputs": [],
      "source": [
        "df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fd5d864",
      "metadata": {
        "id": "8fd5d864"
      },
      "outputs": [],
      "source": [
        "cleaned_path = 'online_retail_cleaned.csv'\n",
        "df.to_csv(cleaned_path, index=False)\n",
        "cleaned_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bbf2be3",
      "metadata": {
        "id": "1bbf2be3"
      },
      "source": [
        "Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f142d682",
      "metadata": {
        "id": "f142d682"
      },
      "source": [
        "## Clean the data PT2.\n",
        "\n",
        "- Remove credit notes (InvoiceNo starting with 'C') if present  \n",
        "- Keep only positive quantities and prices  \n",
        "- Drop rows missing the SKU/StockCode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e353dd73",
      "metadata": {
        "id": "e353dd73"
      },
      "outputs": [],
      "source": [
        "df = df_raw.copy()\n",
        "\n",
        "def _find_col(df, options):\n",
        "    for c in df.columns:\n",
        "        if c.lower() in [o.lower() for o in options]:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "sku_col = _find_col(df, ['StockCode', 'SKU', 'stockcode', 'sku'])\n",
        "if sku_col is None:\n",
        "    raise ValueError('Could not find a SKU column. Expected one of: StockCode, SKU')\n",
        "\n",
        "invoice_col = _find_col(df, ['InvoiceNo', 'Invoice'])\n",
        "qty_col     = _find_col(df, ['Quantity', 'Qty'])\n",
        "price_col   = _find_col(df, ['UnitPrice', 'Price'])\n",
        "if qty_col is None or price_col is None:\n",
        "    raise ValueError(\"Could not find quantity/price columns. Need 'Quantity' & 'UnitPrice' (or 'Qty'/'Price').\")\n",
        "\n",
        "if invoice_col is not None:\n",
        "    df[invoice_col] = df[invoice_col].astype(str)\n",
        "    df = df[~df[invoice_col].str.startswith('C', na=False)]\n",
        "\n",
        "df = df[(df[qty_col] > 0) & (df[price_col] > 0)]\n",
        "df = df.dropna(subset=[sku_col]).copy()\n",
        "\n",
        "df['Revenue'] = df[qty_col] * df[price_col]\n",
        "\n",
        "print(df.shape)\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33479955",
      "metadata": {
        "id": "33479955"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For optional Colab upload\n",
        "try:\n",
        "    from google.colab import files  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.max_columns', 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0628a8a6",
      "metadata": {
        "id": "0628a8a6"
      },
      "source": [
        "## Q1 —  Which products generate the most revenue?\n",
        "This chart ranks the top 10 SKUs by total revenue, highlighting the products that drive sales and should be prioritized for inventory and promotions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4438ede",
      "metadata": {
        "id": "e4438ede"
      },
      "outputs": [],
      "source": [
        "topn = 10\n",
        "revenue_by_sku = (\n",
        "    df.groupby(sku_col, as_index=False)['Revenue']\n",
        "      .sum()\n",
        "      .sort_values('Revenue', ascending=False)\n",
        "      .head(topn)\n",
        ")\n",
        "\n",
        "display(revenue_by_sku)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(revenue_by_sku[sku_col].astype(str), revenue_by_sku['Revenue'])\n",
        "plt.title('Top-10 SKUs by Revenue — Aidan')\n",
        "plt.xlabel('SKU')\n",
        "plt.ylabel('Revenue (raw scale)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90701144",
      "metadata": {
        "id": "90701144"
      },
      "source": [
        "## Q2 — 2. How do sales trend over time?\n",
        "This chart shows monthly revenue, revealing seasonal peaks and dips to guide staffing, inventory, and campaign timing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5398482",
      "metadata": {
        "id": "d5398482"
      },
      "outputs": [],
      "source": [
        "# Simple sales trends & seasonality (keep it basic)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from calendar import month_abbr\n",
        "\n",
        "# use df if it exists, else df_raw\n",
        "try:\n",
        "    data = df.copy()\n",
        "except NameError:\n",
        "    data = df_raw.copy()\n",
        "\n",
        "# basic prep\n",
        "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'], errors='coerce')\n",
        "data = data.dropna(subset=['InvoiceDate'])\n",
        "data['Revenue'] = data['Quantity'] * data['UnitPrice']\n",
        "data = data[data['Revenue'] > 0]\n",
        "\n",
        "# monthly revenue (line)\n",
        "monthly = data.set_index('InvoiceDate').resample('MS')['Revenue'].sum()\n",
        "plt.plot(monthly.index, monthly.values)\n",
        "plt.title('Monthly Revenue — Aidan')\n",
        "plt.xlabel('Month'); plt.ylabel('Revenue')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# average revenue by month-of-year (bar)\n",
        "moy = monthly.groupby(monthly.index.month).mean()\n",
        "labels = [month_abbr[m] for m in range(1, 13)]\n",
        "vals = [moy.get(m, 0) for m in range(1, 13)]\n",
        "plt.bar(labels, vals)\n",
        "plt.title('Average Revenue by Month — Aidan')\n",
        "plt.xlabel('Month'); plt.ylabel('Avg Monthly Revenue')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "print('Peak month (avg):', month_abbr[moy.idxmax()])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f17b3ba",
      "metadata": {
        "id": "5f17b3ba"
      },
      "source": [
        "### Q3. _Which countries (outside the UK) contribute most to international revenue?e_\n",
        "\n",
        "> This chart ranks non-UK countries by revenue to pinpoint the strongest international markets for localized marketing and distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dbbb64c",
      "metadata": {
        "id": "8dbbb64c"
      },
      "outputs": [],
      "source": [
        "# Top non-UK countries by total revenue\n",
        "req = {\"Country\",\"Revenue\"}\n",
        "if not req.issubset(df.columns):\n",
        "    raise ValueError(f\"Missing columns: {req - set(df.columns)}\")\n",
        "\n",
        "intl = df[df[\"Country\"].astype(str).str.lower() != \"united kingdom\"]\n",
        "top_countries = (\n",
        "    intl.groupby(\"Country\")[\"Revenue\"]\n",
        "        .sum()\n",
        "        .sort_values(ascending=False)\n",
        "        .head(10)\n",
        "        .reset_index()\n",
        ")\n",
        "\n",
        "print(top_countries)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(top_countries[\"Country\"].astype(str), top_countries[\"Revenue\"])\n",
        "ax.set_title(\"International Revenue (Top Countries, excl. UK) — Aidan\")\n",
        "ax.set_xlabel(\"Country\")\n",
        "ax.set_ylabel(\"Total Revenue\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b146823b",
      "metadata": {
        "id": "b146823b"
      },
      "source": [
        "### Q4. _What’s the relationship between unit price and quantity sold?_\n",
        "This scatterplot shows the relationship between unit price and quantity sold; a downward pattern suggests higher prices reduce volume, while an upward pattern suggests the opposite.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f7dc99c",
      "metadata": {
        "id": "8f7dc99c"
      },
      "outputs": [],
      "source": [
        "# Scatter: UnitPrice vs Quantity (clip extreme outliers to see the pattern)\n",
        "req = {\"UnitPrice\",\"Quantity\"}\n",
        "if not req.issubset(df.columns):\n",
        "    raise ValueError(f\"Missing columns: {req - set(df.columns)}\")\n",
        "\n",
        "tmp = df[(df[\"UnitPrice\"] > 0) & (df[\"Quantity\"] > 0)].copy()\n",
        "\n",
        "# Clip extreme tails (99th percentile) for readability\n",
        "q_price = tmp[\"UnitPrice\"].quantile(0.99)\n",
        "q_qty = tmp[\"Quantity\"].quantile(0.99)\n",
        "tmp = tmp[(tmp[\"UnitPrice\"] <= q_price) & (tmp[\"Quantity\"] <= q_qty)]\n",
        "\n",
        "print(\"Points plotted:\", len(tmp))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(tmp[\"UnitPrice\"], tmp[\"Quantity\"], alpha=0.3, s=10)\n",
        "ax.set_title(\"Unit Price vs Quantity Sold — Aidan\")\n",
        "ax.set_xlabel(\"Unit Price\")\n",
        "ax.set_ylabel(\"Quantity\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a2ac825",
      "metadata": {
        "id": "4a2ac825"
      },
      "source": [
        "### Q5.  How can customers be segmented by RFM (Recency, Frequency, Monetary?)\n",
        "This chart groups customers by RFM (High-Value, At-Risk, Occasional), showing where to focus VIP rewards, win-back offers, and nurture campaigns.\n",
        "\n",
        "_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a9df503",
      "metadata": {
        "id": "5a9df503"
      },
      "outputs": [],
      "source": [
        "# Simple RFM segmentation (one cell)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Prep\n",
        "data = df.copy()\n",
        "data[\"InvoiceDate\"] = pd.to_datetime(data[\"InvoiceDate\"], errors=\"coerce\")\n",
        "data[\"Quantity\"] = pd.to_numeric(data[\"Quantity\"], errors=\"coerce\")\n",
        "data[\"UnitPrice\"] = pd.to_numeric(data[\"UnitPrice\"], errors=\"coerce\")\n",
        "data[\"Revenue\"] = data[\"Quantity\"] * data[\"UnitPrice\"]\n",
        "data = data.dropna(subset=[\"CustomerID\",\"InvoiceDate\"])\n",
        "data = data[data[\"Revenue\"] > 0]\n",
        "\n",
        "# 2) Snapshot date and R/F/M\n",
        "snapshot = data[\"InvoiceDate\"].max() + pd.Timedelta(days=1)\n",
        "g = data.groupby(\"CustomerID\")\n",
        "recency   = g[\"InvoiceDate\"].max().apply(lambda d: (snapshot - d).days)\n",
        "frequency = (g[\"InvoiceNo\"].nunique() if \"InvoiceNo\" in data.columns else g.size())\n",
        "monetary  = g[\"Revenue\"].sum()\n",
        "\n",
        "rfm = pd.DataFrame({\"Recency\": recency, \"Frequency\": frequency, \"Monetary\": monetary})\n",
        "\n",
        "# 3) Scores (1–5). For Recency, lower days = higher score.\n",
        "rfm[\"R_Score\"] = pd.qcut(rfm[\"Recency\"],   5, labels=[5,4,3,2,1]).astype(int)\n",
        "# Use pd.cut for Frequency to handle potential duplicate bin edges\n",
        "rfm[\"F_Score\"] = pd.cut(rfm[\"Frequency\"], 5, labels=[1,2,3,4,5], duplicates='drop').astype(int)\n",
        "rfm[\"M_Score\"] = pd.qcut(rfm[\"Monetary\"],  5, labels=[1,2,3,4,5]).astype(int)\n",
        "rfm[\"RFM_Sum\"] = rfm[[\"R_Score\",\"F_Score\",\"M_Score\"]].sum(axis=1)\n",
        "\n",
        "# 4) Simple segments\n",
        "def seg(row):\n",
        "    if row[\"RFM_Sum\"] >= 13: return \"High-Value\"\n",
        "    if row[\"R_Score\"] <= 2 and row[\"F_Score\"] <= 2: return \"At-Risk\"\n",
        "    return \"Occasional\"\n",
        "rfm[\"Segment\"] = rfm.apply(seg, axis=1)\n",
        "\n",
        "# 5) Output + quick chart\n",
        "counts = rfm[\"Segment\"].value_counts()\n",
        "print(counts)\n",
        "counts.plot(kind=\"bar\")\n",
        "plt.title(\"Customer Segments (RFM) — Aidan\")\n",
        "plt.xlabel(\"Segment\"); plt.ylabel(\"Customers\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "rfm.head()\n",
        "tmp = df[(df['UnitPrice']>0)&(df['Quantity']>0)].copy()\n",
        "up99, q99 = tmp['UnitPrice'].quantile(0.99), tmp['Quantity'].quantile(0.99)\n",
        "tmp = tmp[(tmp['UnitPrice']<=up99)&(tmp['Quantity']<=q99)]\n",
        "r = tmp['UnitPrice'].corr(tmp['Quantity'])\n",
        "\n",
        "import numpy as np\n",
        "b1 = np.polyfit(np.log(tmp['UnitPrice']), np.log(tmp['Quantity']), 1)[0]  # ~elasticity\n",
        "print(f\"Price–Qty: r = {r:.2f}; elasticity ≈ {b1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34cac206",
      "metadata": {
        "id": "34cac206"
      },
      "source": [
        "### Interpretation of Graphs\n",
        "\n",
        "Top-10 Products (bar): Revenue is concentrated in a small set of SKUs, highlighting clear priorities for inventory and promotion.\n",
        "\n",
        "Monthly Revenue (line): Sales move in a seasonal pattern with distinct peaks and troughs across the timeline.\n",
        "\n",
        "Monthly Revenue + 3-mo MA (line): The smoothed line reveals the underlying direction of sales beyond month-to-month noise.\n",
        "\n",
        "Avg Revenue by Month-of-Year (bar): Certain calendar months consistently outperform others, confirming seasonality at the month level.\n",
        "\n",
        "Avg Revenue by Day-of-Week (bar): Sales are uneven across the week, with some days reliably stronger and others consistently softer.\n",
        "\n",
        "RFM Segments (bar): Most customers cluster into Occasional/At-Risk groups while a smaller High-Value segment delivers outsized impact.\n",
        "\n",
        "Top Countries ex-UK (bar): A few non-UK markets dominate international revenue, indicating where localization will pay off first.\n",
        "\n",
        "Unit Price vs Quantity (scatter): Higher prices generally align with lower quantities (and vice-versa), with clusters showing common price–volume patterns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fccdc891",
      "metadata": {
        "id": "fccdc891"
      },
      "source": [
        "## Conclusions & Recommendations\n",
        "\n",
        "**Insights discovered:**\n",
        "Q1 (Top products): #1 21175 at 3,656; #2 85099B $3,056, #3 47566 $2,116 (also 22112 $1,514, 85123A $1,195, 22730 $1,126).\n",
        "\n",
        "Q2 (Trend): Peak month (avg) = November.\n",
        "\n",
        "Q3 (International): Top non-UK markets: EIRE $6,090, Netherlands $4,975, Germany $4,357, France $3,892.\n",
        "\n",
        "Q4 From 9,630 transactions, unit price and quantity show a moderate negative relationship (r = −0.26); a log–log fit gives elasticity ≈ −0.54 (≈1% price ↑ → ~0.54% units ↓). Most sales cluster at <$5 and <10 units, while items >$10 rarely sell in high quantities.\n",
        "\n",
        "Q5 (RFM): Occasional 59.8% (1,439), At-Risk 40.0% (961), High-Value 0.2% (5) of 2,405 customers\n",
        "\n",
        "**Recommendations to client:**\n",
        "- Q1: Prioritize inventory and promotions for the top SKUs; verify margins before scaling spend.\n",
        "- Q2: Staff up and build inventory ahead of peak months; time campaigns 2–3 weeks before peaks.\n",
        "- Q3: Offer VIP perks to High-Value customers, run win-back offers for At-Risk, and nurture Occasional buyers.\n",
        "- Q4: Localize marketing, currency, and shipping for top non-UK countries; explore regional distributors.\n",
        "- Q5: A/B test price tiers/bundles and avoid blanket discounts on price-insensitive items.\n",
        "\n",
        "**Future work:**\n",
        "- Q1: Analyze SKU-level profitability and attachment (bundle) opportunities.\n",
        "- Q2: Build a seasonal forecast with holiday flags to predict next-quarter revenue.\n",
        "- Q3: Test segmentation-specific campaigns and measure lift vs. control groups.\n",
        "- Q4: Compare CAC, LTV, and margins by country; pilot localized landing pages.\n",
        "- Q5: Estimate price elasticity by SKU controlling for seasonality and promotions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de32a3a9",
      "metadata": {
        "id": "de32a3a9"
      },
      "source": [
        "## Appendix — Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cb270c6",
      "metadata": {
        "id": "9cb270c6"
      },
      "outputs": [],
      "source": [
        "import platform, sys, pandas, numpy, matplotlib\n",
        "print(\"Python:\", platform.python_version())\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"pandas:\", pandas.__version__)\n",
        "print(\"numpy:\", numpy.__version__)\n",
        "print(\"matplotlib:\", matplotlib.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Citations\n",
        "Dataset: Online Retail (UCI ML Repository)\n",
        "\n",
        "APA: Chen, D. (2015). Online Retail [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C5BW33.\n",
        "UCI Machine Learning Repository\n",
        "\n",
        "MLA: Chen, Daqing. Online Retail. UCI Machine Learning Repository, 2015. doi:10.24432/C5BW33."
      ],
      "metadata": {
        "id": "bW1dD3_BIsrM"
      },
      "id": "bW1dD3_BIsrM"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}